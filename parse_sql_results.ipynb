{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_conversations(file_path):\n",
    "    # Structure: {language: {conversation_hash: count, 'total_unique': count, 'total_occurrences': count}}\n",
    "    language_data = defaultdict(lambda: {'unique_conversations': set(), 'total_occurrences': 0})\n",
    "\n",
    "    with open(file_path, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            conversation_hash = row['conversation_hash']\n",
    "            language = row['language']\n",
    "\n",
    "            # Track data per language\n",
    "            lang_data = language_data[language]\n",
    "\n",
    "            # Add to unique conversations if not already present\n",
    "            if conversation_hash not in lang_data['unique_conversations']:\n",
    "                lang_data['unique_conversations'].add(conversation_hash)\n",
    "\n",
    "            # Increment total occurrences\n",
    "            lang_data['total_occurrences'] += 1\n",
    "\n",
    "    # Convert sets to counts and prepare final output\n",
    "    result = {}\n",
    "    for language, data in language_data.items():\n",
    "        result[language] = {\n",
    "            'unique_conversations': len(data['unique_conversations']),\n",
    "            'total_occurrences': data['total_occurrences']\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique conversations and total occurrences per language:\n",
      "Language: c\n",
      "  Unique conversations: 18\n",
      "  Total occurrences: 199\n",
      "Language: csharp\n",
      "  Unique conversations: 46\n",
      "  Total occurrences: 156\n",
      "Language: java\n",
      "  Unique conversations: 82\n",
      "  Total occurrences: 705\n",
      "Language: javascript\n",
      "  Unique conversations: 122\n",
      "  Total occurrences: 616\n",
      "Language: php\n",
      "  Unique conversations: 102\n",
      "  Total occurrences: 328\n",
      "Language: python\n",
      "  Unique conversations: 600\n",
      "  Total occurrences: 5310\n"
     ]
    }
   ],
   "source": [
    "file_path = 'codegrep_results_sql.csv'\n",
    "language_conversations = count_conversations(file_path)\n",
    "\n",
    "unique_convo_hash_good = 0\n",
    "# Print results\n",
    "print(\"Unique conversations and total occurrences per language:\")\n",
    "for language, data in language_conversations.items():\n",
    "    print(f\"Language: {language}\")\n",
    "    unique_convo_hash_good += data['unique_conversations']\n",
    "    print(f\"  Unique conversations: {data['unique_conversations']}\")\n",
    "    print(f\"  Total occurrences: {data['total_occurrences']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_rules = {\n",
    "    \"java\": [\n",
    "        \"tainted-sql-string\",\n",
    "        \"tainted-sqli\",\n",
    "        \"hibernate-sqli\",\n",
    "        \"jdbc-sqli\",\n",
    "        \"jdo-sqli\",\n",
    "        \"jpa-sqli\",\n",
    "        \"tainted-sql-from-http-request\",\n",
    "        \"turbine-sqli\",\n",
    "        \"vertx-sqli\",\n",
    "        \"mongodb-nosqli\",\n",
    "        \"tainted-sql-string\",\n",
    "    ],\n",
    "    \"csharp\": [\n",
    "        \"csharp-sqli\",\n",
    "    ],\n",
    "    \"javascript\": [\n",
    "        \"knex-sqli\",\n",
    "        \"mysql-sqli\",\n",
    "        \"pg-sqli\",\n",
    "        \"sequelize-sqli\",\n",
    "        \"tainted-sql-string\",\n",
    "        \"node-knex-sqli\",\n",
    "        \"node-mssql-sqli\",\n",
    "        \"node-mysql-sqli\",\n",
    "        \"node-postgres-sqli\",\n",
    "    ],\n",
    "    \"php\": [\n",
    "        \"tainted-sql-string\",\n",
    "        \"laravel-sql-injection\",\n",
    "        \"wp-sql-injection-audit\",\n",
    "        \"\",\n",
    "    ],\n",
    "    \"python\": [\n",
    "        \"mysql-sqli\",\n",
    "        \"psycopg-sqli\",\n",
    "        \"pymssql-sqli\",\n",
    "        \"pymysql-sqli\",\n",
    "        \"sqlalchemy-sqli\",\n",
    "        \"tainted-sql-string\",\n",
    "        \"sql-injection-using-extra-where\",\n",
    "        \"sql-injection-using-rawsql\",\n",
    "        \"sql-injection-db-cursor-execute\",\n",
    "        \"sql-injection-using-raw\",\n",
    "        \"aiopg-sqli\",\n",
    "        \"asyncpg-sqli\",\n",
    "        \"pg8000-sqli\",\n",
    "        \"pyramid-sqlalchemy-sql-injection\",\n",
    "        \"sqlalchemy-sql-injection\",\n",
    "        \"sqlalchemy-execute-raw-query\",\n",
    "        \"avoid-sqlalchemy-text\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java 11\n",
      "csharp 1\n",
      "javascript 9\n",
      "php 4\n",
      "python 17\n"
     ]
    }
   ],
   "source": [
    "for key, value in allowed_rules.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules and their Occurrences (unique conversation hashes and total occurrences):\n",
      "Rule: csharp-sqli, Unique Conversation Hashes Count: 3\n",
      "Rule: jdbc-sqli, Unique Conversation Hashes Count: 4\n",
      "Rule: tainted-sql-string, Unique Conversation Hashes Count: 11\n",
      "Rule: sqlalchemy-execute-raw-query, Unique Conversation Hashes Count: 42\n",
      "Rule: psycopg-sqli, Unique Conversation Hashes Count: 5\n",
      "Rule: sql-injection-db-cursor-execute, Unique Conversation Hashes Count: 3\n",
      "Rule: avoid-sqlalchemy-text, Unique Conversation Hashes Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Flatten the allowed rules into a single list\n",
    "allowed_rules_list = [rule for sublist in allowed_rules.values() for rule in sublist]\n",
    "results = defaultdict(lambda: {\"count\": 0, \"hashes\": set()})\n",
    "# Read the CSV file\n",
    "with open('codegrep_results.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        error_id = row['error_id'].split('.')[-1]  # Extract the last part of the error_id\n",
    "        if error_id in allowed_rules_list:\n",
    "            conversation_hash = row['conversation_hash']\n",
    "            if error_id in results:\n",
    "                # Update the count and add the hash to the set\n",
    "                results[error_id][\"count\"] += 1\n",
    "                results[error_id][\"hashes\"].add(conversation_hash)\n",
    "            else:\n",
    "                # Initialize a new entry\n",
    "                results[error_id] = {\"count\": 1, \"hashes\": {conversation_hash}}         \n",
    "            \n",
    "print(\"Rules and their Occurrences (unique conversation hashes and total occurrences):\")\n",
    "for rule in results:\n",
    "    count = results[rule][\"count\"]\n",
    "    unique_hashes = results[rule][\"hashes\"]\n",
    "    print(f\"Rule: {rule}, Unique Conversation Hashes Count: {len(unique_hashes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_convo_hash_bad = 0\n",
    "for rule in results:\n",
    "    count = results[rule][\"count\"]\n",
    "    unique_hashes = results[rule][\"hashes\"]\n",
    "    unique_convo_hash_bad += len(unique_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970 70\n",
      "0.07216494845360824\n"
     ]
    }
   ],
   "source": [
    "print(unique_convo_hash_good, unique_convo_hash_bad)\n",
    "print(unique_convo_hash_bad / unique_convo_hash_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the results in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/sql_occurrences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Rule\", \"Unique Hash Count\", \"Hashes\"])\n",
    "    for rule, data in results.items():\n",
    "        writer.writerow([\n",
    "            rule,\n",
    "            len(data[\"hashes\"]),\n",
    "            \";\".join(data[\"hashes\"])\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
