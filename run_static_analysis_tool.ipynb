{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the necessary tools for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/opengrep/opengrep-rules.git\n",
    "!curl -fsSL https://raw.githubusercontent.com/opengrep/opengrep/main/install.sh | bash\n",
    "!pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from pandas import DataFrame\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "  df: DataFrame  = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"wilfriedkonan/cod-blocks\",\n",
    "    file_path,\n",
    "  )\n",
    "  return df\n",
    "\n",
    "datasets = {\n",
    "    \"c\": \"c.json\",\n",
    "    \"csharp\": \"csharp.json\",\n",
    "    \"html\": \"html.json\",\n",
    "    \"java\": \"java.json\",\n",
    "    \"javascript\": \"javascript.json\",\n",
    "    \"php\": \"php.json\",\n",
    "    \"python\": \"python.json\",\n",
    "    \"sql\": \"sql.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through each language in the Kaggle dataset and turning the .json files into actual files, then saving them to files/LANGUAGE/codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csharp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=html.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.07M/4.07M [00:00<00:00, 8.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=java.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7.96M/7.96M [00:00<00:00, 9.97MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=javascript.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32.6M/32.6M [00:02<00:00, 12.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "php\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=php.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.23M/2.23M [00:00<00:00, 5.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=python.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63.6M/63.6M [00:08<00:00, 8.19MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228745/2037043049.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df: DataFrame  = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wilfriedkonan/cod-blocks?dataset_version_number=3&file_name=sql.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.37M/4.37M [00:00<00:00, 8.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "for language in datasets.keys():\n",
    "    os.makedirs(f\"files/{language}/codes/\", exist_ok=True)\n",
    "    os.makedirs(f\"files/{language}/rules/\", exist_ok=True)\n",
    "    print(language)\n",
    "    df = load_dataset(datasets[language])\n",
    "    for index, data_point in df.iterrows():\n",
    "        with open(f\"files/{language}/codes/{data_point['filename']}\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(data_point[\"code\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering for security rules in codegrep-rules repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_security_yaml_rules(src_root: str, dst_root: str):\n",
    "    \"\"\"\n",
    "    Walk src_root, find all .yaml files under any 'security' folder,\n",
    "    and copy them to dst_root, preserving subdirectory structure.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(src_root):\n",
    "        # only consider paths that have 'security' in their hierarchy\n",
    "        if 'security' in root.split(os.sep):\n",
    "            for file in files:\n",
    "                if file.endswith('.yaml'):\n",
    "                    # compute relative path under src_root\n",
    "                    rel_dir = os.path.relpath(root, src_root)\n",
    "                    dst_dir = os.path.join(dst_root, rel_dir)\n",
    "                    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "                    src_file = os.path.join(root, file)\n",
    "                    dst_file = os.path.join(dst_dir, file)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "                    print(f\"Copied: {rel_dir}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in datasets.keys():\n",
    "    if not os.path.exists(f\"opengrep-rules/{language}\"):\n",
    "        continue\n",
    "    copy_security_yaml_rules(f\"opengrep-rules/{language}\", f\"files/{language}/rules/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing static analysis tool\n",
    "Looping through each language and running the codegrep static analysis tool on them, and saving the results in files/language/output.sarif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in datasets.keys():\n",
    "    if os.path.exists(f\"opengrep-rules/{language}\"):\n",
    "        !/root/.opengrep/cli/latest/opengrep scan --sarif-output=files/{language}/output.sarif -f files/{language}/rules files/{language}/codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Sarif files into CSV\n",
    "(for ease of use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in datasets.keys():\n",
    "    if os.path.exists(f\"opengrep-rules/{language}\"):\n",
    "        rows = []\n",
    "        sarif_path = f\"files/{language}/output.sarif\"\n",
    "        if not os.path.exists(sarif_path):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        with open(sarif_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.loads(f.read())\n",
    "            for run in data[\"runs\"]:\n",
    "                for result in run.get(\"results\", []):\n",
    "                    message = result.get(\"message\", {}).get(\"text\", \"\")\n",
    "                    rule_id = result.get(\"ruleId\", \"\")\n",
    "                    \n",
    "                    # Some results may have multiple locations\n",
    "                    for location in result.get(\"locations\", []):\n",
    "                        loc = location.get(\"physicalLocation\", {})\n",
    "                        artifact = loc.get(\"artifactLocation\", {})\n",
    "                        region = loc.get(\"region\", {})\n",
    "\n",
    "                        conversation_hash = artifact.get(\"uri\", \"\").split(\"/\")[-1].split(\"_\")[0]\n",
    "                        code_index = artifact.get(\"uri\", \"\").split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "                        start_line = region.get(\"startLine\", \"\")\n",
    "                        start_column = region.get(\"startColumn\", \"\")\n",
    "\n",
    "                        rows.append([conversation_hash, code_index, start_line, start_column, rule_id, message])\n",
    "\n",
    "        # Write to CSV\n",
    "        csv_path = f\"files/{language}/{language}.csv\" \n",
    "        with open(csv_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"conversation_hash\", \"code_index\", \"error_line\", \"error_character\", \"error_id\", \"error_message\"])\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        print(f\"CSV written to: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
